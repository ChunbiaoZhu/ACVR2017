
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<HTML xmlns="http://www.w3.org/1999/xhtml">
<!-- InstanceBegin template="/Templates/project_template.dwt" codeOutsideHTMLIsLocked="false" --><!-- the above lines are very important to use CSS in order to have same appearance--><!-- General Header (ver.2) -->
<HEAD><META http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<TITLE>CAIP2017</TITLE>
    <LINK href="./main.css" rel="stylesheet" type="text/css">
	
	<!--<script>
	  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

	  ga('create', 'UA-36966695-6', 'mpg.de');
	  ga('send', 'pageview');
	</script>-->
</HEAD>

<BODY> 

<a href="https://github.com/ChunbiaoZhu/ACVR2017" class="github-corner" aria-label="View source on Github"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#fff; color:#151513; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
<!-- <body oncontextmenu="return false" ondragstart="return false" onkeydown="return false" onselectstart="return false"> -->
<DIV id="bodyframe">

<!-- Main Content Body Frame -->
<DIV id="projectbody">
<BR>
 <!-- InstanceBeginEditable name="body frame" -->
 <TABLE width="950" border="0">
   <TBODY>
     <TR>
       <TD colspan="3"><DIV align="center"><STRONG>ICCV2017 - 2017 IEEE International Conference on Computer Vision (Workshop)</STRONG></DIV></TD>
     </TR>
     <TR>
       <TD colspan="3">&nbsp;</TD>
     </TR>
     <TR>
       <TD colspan="3"><DIV align="center" class="xlarge">An Innovative Salient Object Detection Using Center-Dark Channel Prior</DIV></TD>
     </TR>
   </TBODY>
 </TABLE>

<br>
 


<div align = "center">
<div class="authorname" style="font-size:large;line-adjust:0">Chunbiao Zhu<sup>1</sup>, Ge Li<sup>1</sup>, Xiaoqiang Guo<sup>2</sup>, Ronggang Wang<sup>1</sup>, Wenmin Wang<sup>1</sup></div>
<div class="authoraddress" style="line-adjust:0"><sup>1</sup>School of Electronic and Computer Engineering, Shenzhen Graduate School, Peking University, Shenzhen, China <br /> <sup>2</sup>Academy of Broadcasting Science, SAPPRET Beijing, China</div>
<div class="authoremail email" style="line-adjust:0">zhuchunbiao@pku.edu.cn</div>

<br/>
<a href="https://github.com/ChunbiaoZhu/ACVR2017">Source Code Available</a>
</div>
<br>
<br>
<figure align = "center">
<IMG src="./images/fig1.png" width=700> <!-- 850 -->
<br>
<figcaption>Fig.1 The framework of the proposed algorithm.</figcaption>

 <br>


<figure align = "center">
<IMG src="./images/fig2.png" width=700> <!-- 850 -->
<br>
<figcaption>Fig.2 Visual Process of Our Framework.</figcaption>


</figure>
 
<br>
 
<TABLE width="910" border="0">
  <TBODY>
	<TR>
		<TD width="10"></TD>
		<TD class="large" align = "justify">Abstract</TD>
    </TR>
    <TR>
		<TD width="10"></TD>
        <TD width="400"><div align="justify">Saliency detection aims to detect the most attractive objects in images, which has been widely used as a foundation for various multimedia applications. In this paper, we propose a novel salient object detection algorithm for RGB-D images using center-dark channel prior. First, we generate an initial saliency map based on color saliency map and depth saliency map of a given RGB-D image. Then, we generate a center-dark channel map based on centre saliency prior and dark channel prior. Finally, we fuse the initial saliency map with centre dark channel map to generate the final saliency map. The proposed algorithm is evaluated on two public RGB-D datasets, and the experimental results show that our method outperforms the state-of-the-art methods.
<TD width="20"></TD>
</div>
		</TD>
    </TR>
	</TBODY>
</TABLE>

<!-- <br>
<TABLE>
	<TBODY>
    <TR>
		<TD width="75">&nbsp;</TD>
        <TD>
		<PRE>@inproceedings{Kwon:2015:TPAMI<BR> author = {Younghee Kwon and Kwang In Kim and James Tompkin and Jin Hyung Kim and Christian Theobalt},<BR> title = {Efficient Learning of Image Super-resolution and Compression Artifact Removal<BR>		  with Semi-local {Gaussian} Processes},<BR> booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},<BR> volume = {37},<BR> number = {9},<BR> pages = {1792--1805},<BR> year = {2015}<BR>}</PRE>
		</TD>
    </TR>
  </TBODY>
</TABLE>	 -->

<!-- <br>
<TABLE>
	<TBODY>
	<TR>
		<TD>
		 <TABLE border="0" align="center">
		 <TBODY>
			<TR>
				<TD width="250"></TD>
				<TD align="center" valign="middle"><A href="./EfficientLearning-basedImageEnhancement_TPAMI2014_Paper.pdf" target="_self"><IMG src="./paper_thumbnail.png" BORDER=0 ></A></TD>
				<TD width="130"></TD>
				<TD>&nbsp;&nbsp;&nbsp;<A href="./EfficientLearning-basedImageEnhancement_TPAMI2014_Supplemental.pdf" target="_self"><IMG src="./supplemental_thumbnail.png" BORDER=0 ></A></TD>
			</TR>
			<TR>
				<TD width="55"></TD>
				<TD align="center" valign="top">
				Paper<BR>
				<A href="./EfficientLearning-basedImageEnhancement_TPAMI2014_Paper.pdf" target="_self">PDF (3 MB)</A>
				</TD>
				<TD width="130">&nbsp;</TD>
				<TD align="center" valign="top">
				Supplemental Material<BR>
				<A href="./EfficientLearning-basedImageEnhancement_TPAMI2014_Supplemental.pdf" target="_self">PDF (32 MB)</A>
				</TD>
			</TR>

		 </TBODY>
		 </TABLE>
		</TD>
	</TR>
</TABLE> -->

<br><br><hr width='920'><br><br>

<TABLE width="910" border="0">
  <TBODY>
	<TR>
		
		<TD class="large" align = "center">Experimental Results </TD>
		<TD width="20"></TD>
    </TR>
	</TBODY>
</TABLE>
 <br>


<figure align = "center" > 
<IMG src="./images/fig3.png" width=800 > <!-- 850 -->

<br>
<figcaption align = "center">Fig.3 PR curve and ROC curve of different methods on two datasets.</figcaption>


</figure>

 <br>


 <br>


<figure align = "center" > 
<IMG src="./images/fig4.png" width=800 > <!-- 850 -->

<br>
<figcaption align = "center">Fig.5 Visual comparison of saliency maps on two datasets. (a) - (j) represent: original images, ground truth, FT, SIM, HS, BSCA, LPS,
RGBD1, RGBD2 and OURS, respectively. 

.</figcaption>


</figure>

<br>

<figure align = "center" > 
<IMG src="./images/fig5.png" width=800 > <!-- 850 -->

<br>
<figcaption align = "center">Fig.5 The proposed algorithm is transplanted in small target detection. (a1)-(a5) represent different frames of original video.(b1)-(b5)
represent different frames of the proposed priors detection results.(c1)-(c5) represent different frames of the proposed algorithm detection
results. (d1)-(d5) represent different frames of the ground truth.

.</figcaption>


</figure>

<br>

</script>

<hr width='920'><br><br>

<TABLE width="910" border="0">
  <TBODY>
	<TR>
		<TD width="10"></TD>
		<TD class="large">Acknowledgements</TD>
    </TR>
	<TR>
		<TD height="10"></TD>
    </TR>
	<TR>
		<TD width="10" align = "left"></TD>
		<TD>This work was supported by the grant of National Science Foundation of China (No.U1611461), Shenzhen Peacock Plan (20130408-183003656), and Science and Technology Planning Project of Guangdong Province, China (No. 2014B090910001).</TD>
	</TR>
	<TR>
		<TD height="10"></TD>
    </TR>
<!-- 	<TR>
		<TD width="10"></TD>
		<TD>Images courtesy of <a href="http://www.itl.nist.gov/iad/humanid/feret/feret_master.html">The Facial Recognition Technology (FERET) Database</a>,  
		<a href="http://r0k.us/graphics/kodak/">Kodak Lossless True Color Image Suite</a>,
		<a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/">The Berkeley Segmentation Dataset</a>, <a href="http://en.wikipedia.org/wiki/Lenna">Lena</a> <a href="http://www.ece.rice.edu/~wakin/images/">courtesy</a> of <a href="http://www.computableminds.com/post/lena-soderberg-common-image-processing-test-images.html">Playboy</a>, and <a href="http://nuit-blanche.blogspot.com/2012/03/let-there-be-only-one-fabio.html?m=1">Fabio</a> courtesy of <a href="http://en.wikipedia.org/wiki/Fabio_Lanzoni">Fabio Lanzoni</a> (agent: Eric Ashenberg) via <a href="http://www.cmc.edu/pages/faculty/DNeedell/index.php">Deanna Needell</a> - thanks!</TD>
	</TR> -->
  </TBODY>
</TABLE>


<br><br><br><br>


<!-- InstanceEnd -->
</BODY></HTML>
